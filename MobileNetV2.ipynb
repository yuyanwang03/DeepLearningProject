{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.metrics import classification_report\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from pathlib import Path\n",
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train images: 33595\n",
      "Val images: 7178\n",
      "Classes: ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n"
     ]
    }
   ],
   "source": [
    "# Settings\n",
    "train_dir = Path('./data/train')\n",
    "val_dir   = Path('./data/test')\n",
    "img_size = 48\n",
    "batch_size = 64\n",
    "\n",
    "# Transforms\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((img_size, img_size)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(5),\n",
    "    transforms.RandomAffine(degrees=0, shear=10, translate=(0.2, 0.2)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5]*3, std=[0.5]*3)  # normalize to [-1, 1]\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize((img_size, img_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5]*3, std=[0.5]*3)\n",
    "])\n",
    "\n",
    "# Datasets\n",
    "train_dataset = datasets.ImageFolder(root=train_dir, transform=train_transforms)\n",
    "val_dataset   = datasets.ImageFolder(root=val_dir, transform=val_transforms)\n",
    "print(f\"Train images: {len(train_dataset)}\")\n",
    "print(f\"Val images: {len(val_dataset)}\")\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "# Class names\n",
    "class_names = train_dataset.classes\n",
    "print(\"Classes:\", class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InvertedResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride, expand_ratio):\n",
    "        super().__init__()\n",
    "        self.use_res_connect = stride == 1 and in_channels == out_channels\n",
    "        hidden_dim = in_channels * expand_ratio\n",
    "\n",
    "        layers = []\n",
    "\n",
    "        # Expansion\n",
    "        if expand_ratio != 1:\n",
    "            layers.extend([\n",
    "                nn.Conv2d(in_channels, hidden_dim, kernel_size=1, bias=False),\n",
    "                nn.BatchNorm2d(hidden_dim),\n",
    "                nn.ReLU6(inplace=True)\n",
    "            ])\n",
    "\n",
    "        # Depthwise\n",
    "        layers.extend([\n",
    "            nn.Conv2d(hidden_dim, hidden_dim, kernel_size=3, stride=stride, padding=1, groups=hidden_dim, bias=False),\n",
    "            nn.BatchNorm2d(hidden_dim),\n",
    "            nn.ReLU6(inplace=True)\n",
    "        ])\n",
    "\n",
    "        # Projection\n",
    "        layers.extend([\n",
    "            nn.Conv2d(hidden_dim, out_channels, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels)\n",
    "        ])\n",
    "\n",
    "        self.block = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.use_res_connect:\n",
    "            return x + self.block(x)\n",
    "        else:\n",
    "            return self.block(x)\n",
    "\n",
    "class MobileNetV2_48x48(nn.Module):\n",
    "    def __init__(self, num_classes=7, dropout_rate=0.0):\n",
    "        super().__init__()\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "        # Initial convolution layer\n",
    "        self.init_conv = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1, bias=False),  # 48x48 input\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU6(inplace=True)\n",
    "        )\n",
    "\n",
    "        # Bottleneck configuration: (t, c, n, s)\n",
    "        bottlenecks_cfg = [\n",
    "            (1, 16, 1, 1),\n",
    "            (6, 24, 1, 1),  # no downsampling yet\n",
    "            (6, 32, 2, 2),\n",
    "            (6, 64, 1, 2),\n",
    "            (6, 96, 1, 1),\n",
    "        ]\n",
    "\n",
    "        blocks = []\n",
    "        in_channels = 32\n",
    "        for t, out_channels, n, s in bottlenecks_cfg:\n",
    "            for i in range(n):\n",
    "                stride = s if i == 0 else 1\n",
    "                blocks.append(InvertedResidualBlock(in_channels, out_channels, stride, t))\n",
    "                in_channels = out_channels\n",
    "        self.bottlenecks = nn.Sequential(*blocks)\n",
    "\n",
    "        self.last_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 128, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU6(inplace=True),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.classifier = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.init_conv(x)\n",
    "        x = self.bottlenecks(x)\n",
    "        x = self.last_conv(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 132935\n"
     ]
    }
   ],
   "source": [
    "# Define MobileNetV2 model\n",
    "mobilenet_model = MobileNetV2_48x48(num_classes=len(class_names))\n",
    "total_params = sum(p.numel() for p in mobilenet_model.parameters())\n",
    "print(f\"Total parameters: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "if torch.backends.mps.is_available() and torch.backends.mps.is_built():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "mobilenet_model = MobileNetV2_48x48(num_classes=len(class_names)).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(mobilenet_model.parameters(), lr=1e-3,  weight_decay=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, optimizer, criterion, num_epochs=15, model_name='mobv2_model.pth'):\n",
    "    history = []  # collect metrics per epoch\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss, correct, total = 0, 0, 0\n",
    "        for images, labels in tqdm(train_loader, desc=\"Training\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item() * images.size(0)\n",
    "            _, predicted = outputs.max(1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "        train_acc = correct / total\n",
    "        train_loss /= total\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss, correct, total = 0, 0, 0\n",
    "        y_true, y_pred = [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in tqdm(val_loader, desc=\"Validation\"):\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item() * images.size(0)\n",
    "\n",
    "                _, predicted = outputs.max(1)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "\n",
    "                y_true.extend(labels.cpu().numpy())\n",
    "                y_pred.extend(predicted.cpu().numpy())\n",
    "\n",
    "        val_acc = correct / total\n",
    "        val_loss /= total\n",
    "\n",
    "        # Classification report\n",
    "        report = classification_report(y_true, y_pred, target_names=class_names, output_dict=True)\n",
    "        val_f1_macro = report['macro avg']['f1-score']\n",
    "\n",
    "        epoch_time = time.time() - start_time\n",
    "\n",
    "        # Collect metrics\n",
    "        epoch_data = {\n",
    "            'epoch': epoch + 1,\n",
    "            'train_loss': train_loss,\n",
    "            'val_loss': val_loss,\n",
    "            'train_acc': train_acc,\n",
    "            'val_acc': val_acc,\n",
    "            'val_f1_macro': val_f1_macro,\n",
    "            'epoch_time_sec': epoch_time\n",
    "        }\n",
    "\n",
    "        # Add per-class metrics\n",
    "        for cls in class_names:\n",
    "            for metric in ['precision', 'recall', 'f1-score']:\n",
    "                key = f'{cls}_{metric}'\n",
    "                epoch_data[key] = report[cls][metric]\n",
    "\n",
    "        history.append(epoch_data)\n",
    "\n",
    "        # Console output\n",
    "        print(\"\\nValidation Report:\")\n",
    "        for cls in class_names:\n",
    "            cls_metrics = report[cls]\n",
    "            print(f\"{cls}: Prec={cls_metrics['precision']:.3f} | Rec={cls_metrics['recall']:.3f} | F1={cls_metrics['f1-score']:.3f}\")\n",
    "\n",
    "        print(f\"\\nEpoch Summary: Train Loss={train_loss:.4f} | Val Loss={val_loss:.4f} | Train Acc={train_acc:.3f} | Val Acc={val_acc:.3f}\")\n",
    "        print(f\"Epoch time: {epoch_time:.2f} seconds\")\n",
    "\n",
    "    torch.save(model.state_dict(), f\"results/{model_name}\")\n",
    "    print(f\"Saved model to 'results/{model_name}'\")\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training config: mobv2_adam_lr3_dropout0_bn\n",
      "\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 525/525 [02:23<00:00,  3.65it/s]\n",
      "Validation: 100%|██████████| 113/113 [00:20<00:00,  5.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Report:\n",
      "angry: Prec=0.288 | Rec=0.033 | F1=0.060\n",
      "disgust: Prec=0.015 | Rec=0.090 | F1=0.026\n",
      "fear: Prec=0.231 | Rec=0.023 | F1=0.043\n",
      "happy: Prec=0.392 | Rec=0.805 | F1=0.527\n",
      "neutral: Prec=0.333 | Rec=0.079 | F1=0.128\n",
      "sad: Prec=0.321 | Rec=0.381 | F1=0.348\n",
      "surprise: Prec=0.555 | Rec=0.587 | F1=0.571\n",
      "\n",
      "Epoch Summary: Train Loss=1.6617 | Val Loss=1.6650 | Train Acc=0.350 | Val Acc=0.356\n",
      "Epoch time: 164.02 seconds\n",
      "\n",
      "Epoch 2/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 525/525 [02:17<00:00,  3.82it/s]\n",
      "Validation: 100%|██████████| 113/113 [00:19<00:00,  5.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Report:\n",
      "angry: Prec=0.444 | Rec=0.013 | F1=0.024\n",
      "disgust: Prec=0.017 | Rec=0.459 | F1=0.032\n",
      "fear: Prec=0.304 | Rec=0.014 | F1=0.026\n",
      "happy: Prec=0.794 | Rec=0.414 | F1=0.544\n",
      "neutral: Prec=0.422 | Rec=0.257 | F1=0.320\n",
      "sad: Prec=0.308 | Rec=0.330 | F1=0.319\n",
      "surprise: Prec=0.507 | Rec=0.650 | F1=0.570\n",
      "\n",
      "Epoch Summary: Train Loss=1.4176 | Val Loss=2.1831 | Train Acc=0.460 | Val Acc=0.290\n",
      "Epoch time: 157.36 seconds\n",
      "\n",
      "Epoch 3/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 525/525 [02:13<00:00,  3.94it/s]\n",
      "Validation: 100%|██████████| 113/113 [00:19<00:00,  5.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Report:\n",
      "angry: Prec=0.358 | Rec=0.124 | F1=0.184\n",
      "disgust: Prec=0.020 | Rec=0.477 | F1=0.038\n",
      "fear: Prec=0.214 | Rec=0.126 | F1=0.158\n",
      "happy: Prec=0.810 | Rec=0.487 | F1=0.608\n",
      "neutral: Prec=0.625 | Rec=0.160 | F1=0.255\n",
      "sad: Prec=0.350 | Rec=0.378 | F1=0.363\n",
      "surprise: Prec=0.625 | Rec=0.610 | F1=0.618\n",
      "\n",
      "Epoch Summary: Train Loss=1.3140 | Val Loss=2.0100 | Train Acc=0.500 | Val Acc=0.326\n",
      "Epoch time: 152.65 seconds\n",
      "\n",
      "Epoch 4/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 525/525 [02:16<00:00,  3.84it/s]\n",
      "Validation: 100%|██████████| 113/113 [00:19<00:00,  5.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Report:\n",
      "angry: Prec=0.442 | Rec=0.194 | F1=0.270\n",
      "disgust: Prec=0.018 | Rec=0.045 | F1=0.025\n",
      "fear: Prec=0.291 | Rec=0.142 | F1=0.190\n",
      "happy: Prec=0.586 | Rec=0.875 | F1=0.702\n",
      "neutral: Prec=0.493 | Rec=0.461 | F1=0.477\n",
      "sad: Prec=0.410 | Rec=0.391 | F1=0.400\n",
      "surprise: Prec=0.603 | Rec=0.715 | F1=0.654\n",
      "\n",
      "Epoch Summary: Train Loss=1.2424 | Val Loss=1.3618 | Train Acc=0.530 | Val Acc=0.493\n",
      "Epoch time: 156.40 seconds\n",
      "\n",
      "Epoch 5/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 525/525 [02:15<00:00,  3.89it/s]\n",
      "Validation: 100%|██████████| 113/113 [00:20<00:00,  5.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Report:\n",
      "angry: Prec=0.432 | Rec=0.270 | F1=0.332\n",
      "disgust: Prec=0.037 | Rec=0.171 | F1=0.061\n",
      "fear: Prec=0.302 | Rec=0.083 | F1=0.130\n",
      "happy: Prec=0.537 | Rec=0.869 | F1=0.664\n",
      "neutral: Prec=0.504 | Rec=0.322 | F1=0.393\n",
      "sad: Prec=0.468 | Rec=0.172 | F1=0.252\n",
      "surprise: Prec=0.412 | Rec=0.829 | F1=0.551\n",
      "\n",
      "Epoch Summary: Train Loss=1.1950 | Val Loss=1.5640 | Train Acc=0.548 | Val Acc=0.447\n",
      "Epoch time: 155.39 seconds\n",
      "\n",
      "Epoch 6/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 525/525 [02:10<00:00,  4.04it/s]\n",
      "Validation: 100%|██████████| 113/113 [00:19<00:00,  5.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Report:\n",
      "angry: Prec=0.423 | Rec=0.347 | F1=0.381\n",
      "disgust: Prec=0.034 | Rec=0.117 | F1=0.053\n",
      "fear: Prec=0.268 | Rec=0.233 | F1=0.249\n",
      "happy: Prec=0.655 | Rec=0.823 | F1=0.729\n",
      "neutral: Prec=0.574 | Rec=0.292 | F1=0.387\n",
      "sad: Prec=0.504 | Rec=0.217 | F1=0.304\n",
      "surprise: Prec=0.400 | Rec=0.833 | F1=0.540\n",
      "\n",
      "Epoch Summary: Train Loss=1.1622 | Val Loss=1.4717 | Train Acc=0.560 | Val Acc=0.469\n",
      "Epoch time: 149.46 seconds\n",
      "\n",
      "Epoch 7/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 525/525 [02:24<00:00,  3.63it/s]\n",
      "Validation: 100%|██████████| 113/113 [00:19<00:00,  5.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Report:\n",
      "angry: Prec=0.512 | Rec=0.240 | F1=0.327\n",
      "disgust: Prec=0.057 | Rec=0.216 | F1=0.090\n",
      "fear: Prec=0.345 | Rec=0.157 | F1=0.216\n",
      "happy: Prec=0.654 | Rec=0.821 | F1=0.728\n",
      "neutral: Prec=0.500 | Rec=0.480 | F1=0.490\n",
      "sad: Prec=0.443 | Rec=0.369 | F1=0.403\n",
      "surprise: Prec=0.488 | Rec=0.817 | F1=0.611\n",
      "\n",
      "Epoch Summary: Train Loss=1.1412 | Val Loss=1.3396 | Train Acc=0.570 | Val Acc=0.502\n",
      "Epoch time: 163.75 seconds\n",
      "\n",
      "Epoch 8/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 525/525 [02:22<00:00,  3.70it/s]\n",
      "Validation: 100%|██████████| 113/113 [00:19<00:00,  5.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Report:\n",
      "angry: Prec=0.486 | Rec=0.350 | F1=0.407\n",
      "disgust: Prec=0.065 | Rec=0.135 | F1=0.087\n",
      "fear: Prec=0.350 | Rec=0.269 | F1=0.304\n",
      "happy: Prec=0.829 | Rec=0.740 | F1=0.782\n",
      "neutral: Prec=0.478 | Rec=0.606 | F1=0.534\n",
      "sad: Prec=0.438 | Rec=0.492 | F1=0.463\n",
      "surprise: Prec=0.626 | Rec=0.696 | F1=0.659\n",
      "\n",
      "Epoch Summary: Train Loss=1.1159 | Val Loss=1.2482 | Train Acc=0.581 | Val Acc=0.540\n",
      "Epoch time: 161.63 seconds\n",
      "\n",
      "Epoch 9/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 525/525 [02:49<00:00,  3.10it/s]\n",
      "Validation: 100%|██████████| 113/113 [00:23<00:00,  4.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Report:\n",
      "angry: Prec=0.450 | Rec=0.286 | F1=0.350\n",
      "disgust: Prec=0.051 | Rec=0.514 | F1=0.093\n",
      "fear: Prec=0.404 | Rec=0.128 | F1=0.194\n",
      "happy: Prec=0.727 | Rec=0.781 | F1=0.753\n",
      "neutral: Prec=0.533 | Rec=0.427 | F1=0.474\n",
      "sad: Prec=0.437 | Rec=0.383 | F1=0.408\n",
      "surprise: Prec=0.565 | Rec=0.782 | F1=0.656\n",
      "\n",
      "Epoch Summary: Train Loss=1.0979 | Val Loss=1.4291 | Train Acc=0.583 | Val Acc=0.488\n",
      "Epoch time: 192.93 seconds\n",
      "\n",
      "Epoch 10/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 525/525 [02:40<00:00,  3.27it/s]\n",
      "Validation: 100%|██████████| 113/113 [00:19<00:00,  5.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Report:\n",
      "angry: Prec=0.647 | Rec=0.113 | F1=0.192\n",
      "disgust: Prec=0.033 | Rec=0.586 | F1=0.062\n",
      "fear: Prec=0.314 | Rec=0.233 | F1=0.268\n",
      "happy: Prec=0.839 | Rec=0.566 | F1=0.676\n",
      "neutral: Prec=0.601 | Rec=0.195 | F1=0.295\n",
      "sad: Prec=0.455 | Rec=0.192 | F1=0.270\n",
      "surprise: Prec=0.336 | Rec=0.869 | F1=0.484\n",
      "\n",
      "Epoch Summary: Train Loss=1.0840 | Val Loss=2.1926 | Train Acc=0.591 | Val Acc=0.365\n",
      "Epoch time: 180.24 seconds\n",
      "\n",
      "Epoch 11/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 525/525 [02:30<00:00,  3.49it/s]\n",
      "Validation: 100%|██████████| 113/113 [00:19<00:00,  5.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Report:\n",
      "angry: Prec=0.533 | Rec=0.246 | F1=0.337\n",
      "disgust: Prec=0.051 | Rec=0.649 | F1=0.094\n",
      "fear: Prec=0.334 | Rec=0.175 | F1=0.229\n",
      "happy: Prec=0.819 | Rec=0.723 | F1=0.768\n",
      "neutral: Prec=0.574 | Rec=0.388 | F1=0.463\n",
      "sad: Prec=0.460 | Rec=0.283 | F1=0.351\n",
      "surprise: Prec=0.438 | Rec=0.847 | F1=0.577\n",
      "\n",
      "Epoch Summary: Train Loss=1.0653 | Val Loss=1.6030 | Train Acc=0.600 | Val Acc=0.460\n",
      "Epoch time: 170.13 seconds\n",
      "\n",
      "Epoch 12/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 525/525 [03:15<00:00,  2.68it/s]\n",
      "Validation: 100%|██████████| 113/113 [00:20<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Report:\n",
      "angry: Prec=0.500 | Rec=0.251 | F1=0.334\n",
      "disgust: Prec=0.053 | Rec=0.532 | F1=0.097\n",
      "fear: Prec=0.404 | Rec=0.131 | F1=0.198\n",
      "happy: Prec=0.677 | Rec=0.828 | F1=0.745\n",
      "neutral: Prec=0.481 | Rec=0.524 | F1=0.501\n",
      "sad: Prec=0.583 | Rec=0.163 | F1=0.255\n",
      "surprise: Prec=0.493 | Rec=0.832 | F1=0.619\n",
      "\n",
      "Epoch Summary: Train Loss=1.0551 | Val Loss=1.5317 | Train Acc=0.602 | Val Acc=0.479\n",
      "Epoch time: 216.29 seconds\n",
      "\n",
      "Epoch 13/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 525/525 [02:42<00:00,  3.24it/s]\n",
      "Validation: 100%|██████████| 113/113 [00:19<00:00,  5.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Report:\n",
      "angry: Prec=0.494 | Rec=0.314 | F1=0.384\n",
      "disgust: Prec=0.088 | Rec=0.505 | F1=0.150\n",
      "fear: Prec=0.332 | Rec=0.271 | F1=0.299\n",
      "happy: Prec=0.765 | Rec=0.778 | F1=0.772\n",
      "neutral: Prec=0.606 | Rec=0.181 | F1=0.279\n",
      "sad: Prec=0.587 | Rec=0.149 | F1=0.238\n",
      "surprise: Prec=0.284 | Rec=0.890 | F1=0.431\n",
      "\n",
      "Epoch Summary: Train Loss=1.0381 | Val Loss=1.7415 | Train Acc=0.612 | Val Acc=0.441\n",
      "Epoch time: 182.15 seconds\n",
      "\n",
      "Epoch 14/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 525/525 [02:39<00:00,  3.28it/s]\n",
      "Validation: 100%|██████████| 113/113 [00:19<00:00,  5.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Report:\n",
      "angry: Prec=0.527 | Rec=0.247 | F1=0.337\n",
      "disgust: Prec=0.039 | Rec=0.802 | F1=0.074\n",
      "fear: Prec=0.372 | Rec=0.110 | F1=0.170\n",
      "happy: Prec=0.770 | Rec=0.714 | F1=0.741\n",
      "neutral: Prec=0.657 | Rec=0.143 | F1=0.235\n",
      "sad: Prec=0.489 | Rec=0.129 | F1=0.204\n",
      "surprise: Prec=0.383 | Rec=0.865 | F1=0.531\n",
      "\n",
      "Epoch Summary: Train Loss=1.0281 | Val Loss=2.1480 | Train Acc=0.612 | Val Acc=0.385\n",
      "Epoch time: 179.85 seconds\n",
      "\n",
      "Epoch 15/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 525/525 [02:55<00:00,  2.99it/s]\n",
      "Validation: 100%|██████████| 113/113 [00:19<00:00,  5.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Report:\n",
      "angry: Prec=0.550 | Rec=0.246 | F1=0.340\n",
      "disgust: Prec=0.052 | Rec=0.766 | F1=0.098\n",
      "fear: Prec=0.468 | Rec=0.108 | F1=0.176\n",
      "happy: Prec=0.818 | Rec=0.689 | F1=0.748\n",
      "neutral: Prec=0.577 | Rec=0.320 | F1=0.412\n",
      "sad: Prec=0.479 | Rec=0.211 | F1=0.293\n",
      "surprise: Prec=0.334 | Rec=0.866 | F1=0.483\n",
      "\n",
      "Epoch Summary: Train Loss=1.0190 | Val Loss=1.8732 | Train Acc=0.618 | Val Acc=0.423\n",
      "Epoch time: 195.71 seconds\n",
      "Saved model to 'results/mobv2_adam_lr3_dropout0_bn'\n",
      "\n",
      "Training config: mobv2_adam_lr3_dropout15_bn\n",
      "\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 525/525 [02:37<00:00,  3.33it/s]\n",
      "Validation: 100%|██████████| 113/113 [00:19<00:00,  5.72it/s]\n",
      "/Users/taniapazospuig/Desktop/DeepLearningProject/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/taniapazospuig/Desktop/DeepLearningProject/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/taniapazospuig/Desktop/DeepLearningProject/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Report:\n",
      "angry: Prec=0.000 | Rec=0.000 | F1=0.000\n",
      "disgust: Prec=0.017 | Rec=0.658 | F1=0.033\n",
      "fear: Prec=0.000 | Rec=0.000 | F1=0.000\n",
      "happy: Prec=0.458 | Rec=0.220 | F1=0.298\n",
      "neutral: Prec=0.438 | Rec=0.032 | F1=0.059\n",
      "sad: Prec=0.305 | Rec=0.086 | F1=0.134\n",
      "surprise: Prec=0.358 | Rec=0.670 | F1=0.467\n",
      "\n",
      "Epoch Summary: Train Loss=1.6801 | Val Loss=3.5882 | Train Acc=0.340 | Val Acc=0.163\n",
      "Epoch time: 177.32 seconds\n",
      "\n",
      "Epoch 2/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 525/525 [02:37<00:00,  3.33it/s]\n",
      "Validation: 100%|██████████| 113/113 [00:19<00:00,  5.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Report:\n",
      "angry: Prec=0.239 | Rec=0.011 | F1=0.022\n",
      "disgust: Prec=0.032 | Rec=0.153 | F1=0.053\n",
      "fear: Prec=0.188 | Rec=0.246 | F1=0.213\n",
      "happy: Prec=0.785 | Rec=0.573 | F1=0.663\n",
      "neutral: Prec=0.483 | Rec=0.272 | F1=0.348\n",
      "sad: Prec=0.332 | Rec=0.439 | F1=0.378\n",
      "surprise: Prec=0.406 | Rec=0.792 | F1=0.537\n",
      "\n",
      "Epoch Summary: Train Loss=1.4294 | Val Loss=1.5734 | Train Acc=0.455 | Val Acc=0.395\n",
      "Epoch time: 176.85 seconds\n",
      "\n",
      "Epoch 3/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 525/525 [02:27<00:00,  3.56it/s]\n",
      "Validation: 100%|██████████| 113/113 [00:19<00:00,  5.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Report:\n",
      "angry: Prec=0.305 | Rec=0.189 | F1=0.233\n",
      "disgust: Prec=0.023 | Rec=0.586 | F1=0.044\n",
      "fear: Prec=0.294 | Rec=0.034 | F1=0.061\n",
      "happy: Prec=0.776 | Rec=0.446 | F1=0.567\n",
      "neutral: Prec=0.582 | Rec=0.118 | F1=0.196\n",
      "sad: Prec=0.473 | Rec=0.097 | F1=0.161\n",
      "surprise: Prec=0.340 | Rec=0.859 | F1=0.488\n",
      "\n",
      "Epoch Summary: Train Loss=1.3071 | Val Loss=2.6365 | Train Acc=0.506 | Val Acc=0.286\n",
      "Epoch time: 167.29 seconds\n",
      "\n",
      "Epoch 4/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 11/525 [00:06<05:26,  1.57it/s]"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def build_model(dropout):\n",
    "    return MobileNetV2_48x48(num_classes=len(class_names), dropout_rate=dropout).to(device)\n",
    "\n",
    "# Define settings to test\n",
    "configs = [\n",
    "    # No dropout, no weight decay\n",
    "    {'name': 'baseline_adam_drop0_wd0', 'optimizer': 'adam', 'lr': 1e-3, 'dropout': 0.0, 'weight_decay': 0.0},\n",
    "    # Dropout only\n",
    "    {'name': 'drop15_wd0', 'optimizer': 'adam', 'lr': 1e-3, 'dropout': 0.15, 'weight_decay': 0.0},\n",
    "    # Weight decay only\n",
    "    {'name': 'drop0_wd5e5', 'optimizer': 'adam', 'lr': 1e-3, 'dropout': 0.0, 'weight_decay': 5e-5},\n",
    "    # Combined dropout + weight decay\n",
    "    {'name': 'drop15_wd5e5', 'optimizer': 'adam', 'lr': 1e-3, 'dropout': 0.15, 'weight_decay': 5e-5},\n",
    "    # Same but using SGD to test optimizer difference\n",
    "    {'name': 'drop15_wd5e5_sgd', 'optimizer': 'sgd', 'lr': 1e-2, 'dropout': 0.15, 'weight_decay': 5e-5},\n",
    "]\n",
    "\n",
    "for config in configs:\n",
    "    print(f\"\\nTraining config: {config['name']}\")\n",
    "    model = build_model(config['dropout'])\n",
    "\n",
    "    if config['optimizer'] == 'adam':\n",
    "        optimizer = optim.Adam(model.parameters(), lr=config['lr'], weight_decay=config['weight_decay'])\n",
    "    else:\n",
    "        optimizer = optim.SGD(model.parameters(), lr=config['lr'], momentum=0.9, weight_decay=config['weight_decay'])\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    history = train(model, train_loader, val_loader, optimizer, criterion, num_epochs=15, model_name=config['name'])\n",
    "    pd.DataFrame(history).to_csv(f'results/history_{config[\"name\"]}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train best model for 40 epochs\n",
    "best_dropout = 0.15  # CHANGE DEPENDING ON YOUR BEST CONFIG\n",
    "best_lr = 1e-3\n",
    "best_weight_decay = 5e-5\n",
    "best_optimizer_name = 'adam'  # or 'sgd'\n",
    "\n",
    "model = build_model(best_dropout)\n",
    "if best_optimizer_name == 'adam':\n",
    "    optimizer = optim.Adam(model.parameters(), lr=best_lr, weight_decay=best_weight_decay)\n",
    "else:\n",
    "    optimizer = optim.SGD(model.parameters(), lr=best_lr, momentum=0.9, weight_decay=best_weight_decay)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "history = train(model, train_loader, val_loader, optimizer, criterion, num_epochs=40, model_name='mobv2_final_model.pth')\n",
    "pd.DataFrame(history).to_csv(f'results/history_mobv2_final_model.csv', index=False)\n",
    "df_metrics = pd.DataFrame(history)\n",
    "display(df_metrics.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
